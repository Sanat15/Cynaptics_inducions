{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow-datasets\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(ds.as_numpy_iterator())\n",
    "print(first_batch.keys())  # Should output: dict_keys(['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataiterator = ds.as_numpy_iterator() # set up a connection to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(dataiterator.next()['image']).shape  # get the next batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Path to your custom dataset\n",
    "CUSTOM_DATASET_DIR = \"C:/Users/HP/Documents/Programs/Cynaptics/Data/Train/Real\"\n",
    "\n",
    "# Function to preprocess and load images\n",
    "def load_and_preprocess_image(image_path, target_size=(28, 28)):\n",
    "    image_path = image_path.numpy().decode('utf-8')  # Convert TensorFlow tensor to Python string\n",
    "    image = load_img(image_path, target_size=target_size, color_mode=\"grayscale\")  # Fashion MNIST is grayscale\n",
    "    image = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Wrapper to handle `numpy()` conversion in the map function\n",
    "def load_and_preprocess_image_wrapper(image_path, target_size=(28, 28)):\n",
    "    return tf.py_function(func=load_and_preprocess_image, inp=[image_path], Tout=tf.float32)\n",
    "\n",
    "# Function to create a TensorFlow Dataset\n",
    "def create_custom_dataset(directory, target_size=(28, 28), batch_size=32):\n",
    "    image_paths = [os.path.join(directory, fname) for fname in os.listdir(directory) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    labels = [0] * len(image_paths)  # Dummy labels, as the dataset has no explicit labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: {'image': load_and_preprocess_image_wrapper(x, target_size), 'label': y}, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Create the custom dataset\n",
    "ds = create_custom_dataset(CUSTOM_DATASET_DIR)\n",
    "\n",
    "# Visualization of Images with Matplotlib\n",
    "dataiterator = iter(ds)  # Create an iterator for the dataset\n",
    "\n",
    "# Set up the sub-plot format\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))  # fig is the whole plot, ax is each subplot\n",
    "for idx in range(4):\n",
    "    # Grab an image and label\n",
    "    batch = next(dataiterator)  # A sample\n",
    "    image = np.squeeze(batch['image'][idx].numpy())  # Extract the image and remove batch dimensions\n",
    "    label = batch['label'][idx].numpy()  # Extract the corresponding label\n",
    "    # Plot the image using a specific axis\n",
    "    ax[idx].imshow(image, cmap='gray')  # Display the grayscale image\n",
    "    ax[idx].set_title(f\"Label: {label}\")  # Append image label as plot title\n",
    "    ax[idx].axis('off')  # Hide axes for clarity\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing , scaling images to 0-1\n",
    "def scale_images(data):\n",
    "  image = data['image']\n",
    "  return image/ 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "ds = tfds.load('fashion_mnist', split='train') # Reloaded dataset , optional\n",
    "ds = ds.map(scale_images) # Running dataset through the scaling function\n",
    "ds = ds.cache() # Caching the dataset for that batch\n",
    "ds = ds.shuffle(60000) #Shuffling the dataset\n",
    "ds = ds.batch(128) # Dividing the dataset into batches of 128\n",
    "ds = ds.prefetch(64)  # Eliminates bottelneckind by prefetching the next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in sqquential api for generator and discriminator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Reshape , Flatten, Conv2D, Dropout,UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Takes in random values and reshapes it to 7x7x128\n",
    "    # Beginnings of a generated image\n",
    "    model.add(Dense(7*7*128, input_dim=128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "    \n",
    "    # Upsampling block 1 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Upsampling block 2 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional block 1\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional block 2\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Conv layer to get to one channel\n",
    "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the generator\n",
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "# Set up the sub-plot format\n",
    "\n",
    "fig ,ax = plt.subplots(ncols = 4,figsize=(20,20)) # fig is whole plot , ax is each subplot\n",
    "for idx , img in enumerate(img):\n",
    "\n",
    "  #Plot the image using a spicific axis\n",
    "  ax[idx].imshow(np.squeeze(img)) # plot using a specific subplot\n",
    "  ax[idx].set_title(idx) #Appending image lable as plot title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "  model = Sequential()\n",
    "  \n",
    "  #First Conv block\n",
    "  model.add(Conv2D(32 , 5, input_shape=(28,28,1)))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  #Second Conv block\n",
    "  model.add(Conv2D(64 , 5))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  #Third Conv block\n",
    "  model.add(Conv2D(128 , 5))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  #Forth Conv block\n",
    "  model.add(Conv2D(256 , 5))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  #Flatten then pass through dense layer\n",
    "  model.add(Flatten())\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.predict(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the optimizer and loss function\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(learning_rate=0.0001)\n",
    "d_opt = Adam(learning_rate=0.00001)\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mporting base model class into sub-class\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model): \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # Pass through args and kwargs to base class \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for gen and disc\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
    "        # Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for losses and optimizers\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss \n",
    "\n",
    "    def train_step(self, batch):\n",
    "        # Get the data \n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as d_tape: \n",
    "            # Pass the real and fake images to the discriminator model\n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            \n",
    "            # Create labels for real and fakes images\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            \n",
    "            # Add some noise to the TRUE outputs\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            # Calculate loss - BINARYCROSS \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Apply backpropagation - nn learn \n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train the generator \n",
    "        with tf.GradientTape() as g_tape: \n",
    "            # Generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
    "                                        \n",
    "            # Create the predicted labels\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "                                        \n",
    "            # Calculate loss - trick to training to fake out the discriminator\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        # Apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create instance of the subclass model\n",
    "gan = GAN(generator , discriminator)\n",
    "#Compile the model\n",
    "gan.compile(g_opt , d_opt , g_loss , d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('generated_images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = gan.fit(ds , epochs = 2000 ,callbacks = [ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['d_loss'], label='Discriminator Loss')\n",
    "plt.plot(hist.history['g_loss'], label='Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = generator(tf.random.normal((16 , 128 , 1)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(ncols = 4,nrows =4, figsize=(20,20))\n",
    "for idx in range(4):\n",
    "  for c in range(4):\n",
    "    ax[idx][c].imshow(imgs[(idx+1)*(c+1)-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
